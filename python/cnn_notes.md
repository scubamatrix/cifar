# [Convolutional Neural Networks (CNN) for CIFAR-10 Dataset](http://parneetk.github.io/blog/cnn-cifar10/)


# [Achieving 90% accuracy in Object Recognition Task on CIFAR-10 Dataset with Keras: Convolutional Neural Networks](https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/)

1. Deep Neural Network Architecture

We saw previously that shallow architecture was able to achieve 76% accuracy only. So, the idea here is to build a deep neural architecture as opposed to shallow architecture which was not able to learn features of objects accurately.

The advantage of multiple layers is that they can learn features at various levels of abstraction. For example, if you train a deep CNN to classify images, you will find that the first layer will train itself to recognize very basic things like edges, the next layer will train itself to recognize collections of edges such as shapes, the next layer will train itself to recognize collections of shapes like wheels, legs, tails, faces and the next layer will learn even higher-order features like objects (truck, ships, dog, frog etc). Multiple layers are much better at generalizing because they learn all the intermediate features between the raw input and the high-level classification. At the same time, there are few important aspects which need to be taken care off to prevent over-fitting. Deep CNN are harder to train because:

a) Data requirement increases as the network becomes deeper.
b) Regularization becomes important as number of parameters (weights) increases in order to do learning of weights from memorization of features towards generalization of features.

Therefore, we will build a 6-layered convolution neural network (CNN) followed by a flatten layer. The output layer is dense layer of 10 nodes (as there are 10 classes) with softmax activation. Here is a model summary:

The convolution layer is set of 3 operations: Convolution, Activation & Batch normalization. Sometimes, Dropout layer is kept after Pooling in lieu of regularization. Also, multiple dense layer can be kept after flattening layer before finally keeping output dense layer. These are some general trends/norms which I have come across in designing CNN architectures.

2. Data Augmentation

In Keras, we can use the `ImageDataGenerator` class to generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely. The image data is generated by transforming the actual training images by rotation, crop, shifts, shear, zoom, flip, reflection, normalization etc. The below code snippets shows how to initialize the image data generator class.

3. Regularization

Deep neural nets with a large number of parameters are very powerful machine learning systems. However, _overfitting_ is a serious problem in such networks.  Given below are a few techniques which were proposed recently and have become a general norm these days in CNNs.

**Dropout** is a technique for addressing the overfitting problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. The reduction in number of parameters in each step of training has the effect of regularization. Dropout has shown improvements in the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification, and computational biology, obtaining state-of-the-art results on many benchmark data sets [1].

**Kernel_regularizer** allows us to apply penalties on layer parameters during optimization. These penalties are incorporated in the loss function that the network optimizes. This argument in the convolutional layer is nothing but L2 regularization of the weights. This penalizes peaky weights and makes sure that all the inputs are considered. During gradient descent parameter update, the above L2 regularization means that every weight is decayed linearly, which is why it is called _weight decay_.

**BatchNormalization** normalizes the activation of the previous layer at each batch -- applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1. It addresses the problem of _internal covariate shift_. It also acts as a regularizer, in some cases eliminating the need for Dropout. Batch Normalization achieves the same accuracy with fewer training steps thus speeding up the training process [2].

Having read a brief description of all the concepts that we are going to use here, Let’s look into full python implementation of object recognition task on CIFAR-10 dataset.

## More on Results

Let us check out a few images from the test-set to find out the object class predicted by our trained CNN. We will call the `show_imgs(X)` method defined in the first section "CIFAR-10 task – Object Recognition in Images" to display 16 images in a 4x4 grid. Now, the trained CNN model is loaded into memory from disk and we predict the object class of the first 16 images from test-set.

Images must be Z-score (mean-std) normalized because that is how we have implemented while training. Z-score normalization is important because it results in similarly-ranged feature values and that the gradients do not go out of control (need one global learning rate multiplier).





--------------------


# [Image Augmentation for Deep Learning using Keras and Histogram Equalization](https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085)

## Image Augmentation: What is it? Why is it important?

Deep Neural Networks, particularly Convolutional Neural Networks (CNNs), are particularly proficient at image classification tasks. State-of-the-art CNNs have even been shown to exceed human performance in image recognition.

However, gathering images as training data can be both costly and time consuming.

In order to combat the high expense of collecting thousands of training images, **image augmentation** has been developed in order to generate training data from an existing dataset.

Image Augmentation is the process of taking images that are already in a training dataset and manipulating them to create many altered versions of the same image. This both provides more images to train on, but can also help expose our classifier to a wider variety of lighting and coloring situations so as to make our classifier more robust.

## Using Keras for Basic Image Augmentation

There are many ways to pre-process images. In this post, we will go over some of the most common out-of-the-box methods that the keras deep learning library provides for augmenting images. Then, we will show how to alter the `keras.preprocessing_image.py` file in order to enable histogram equalization methods. We will use the cifar10 dataset that comes with keras. However, we will only be using the images of cats and dogs from the dataset in order to keep the task small enough to be performed on a CPU — in case you want to follow along. You can view an IPython notebook of the source code from this post.

### Loading and Formatting the Data

The first thing that we will do is load the cifar10 dataset and format the images to prepare them for the CNN. We will also take a peek at a few of the images just to make sure the data has loaded properly.

### Create an image generator from ImageDataGenerator()

Augmenting our image data with keras is rather simple.

1. We need to create an image generator by calling the `ImageDataGenerator()` function and pass it a list of parameters describing the alterations that we want it to perform on the images.

2. We call the `fit()` function on our image generator which will apply the changes to the images batch by batch. By default, the modifications will be applied randomly, so not every image will be changed every time.

You can also use `keras.preprocessing` to export augmented image files to a folder in order to build up a giant dataset of altered images should you desire to do so.

We will look at some of the more visually interesting augmentations here. A description of all of the possible ImageDataGenerator() parameters as well as a list of the other methods available in keras.preprocessing can be seen in the keras documentation.

- Randomly Rotate Images
- Flip Images Vertically
- Shift Images Vertically or Horizontally by 20%

## Histogram Equalization Techniques

Histogram Equalization is the process of taking a low contrast image and increasing the contrast between the image’s relative highs and lows in order to bring out subtle differences in shade and create a higher contrast image. The results can be striking, especially for grayscale images.

In this post we will be looking at three image augmentation techniques for improving contrast in images. These approaches are sometimes also referred to as “Histogram Stretching” because they take the distribution of pixel intensities and stretch the distribution to fit a wider range of values thereby increasing the level of contrast between the lightest and darkest portions of an image.

- Histogram Equalization
- Contrast Stretching
- Adaptive Equalization

## Modifying keras.preprocessing to enable Histogram Equalization techniques.

Now that we have successfully modified one image from the cifar10 dataset, we will demonstrate how to alter the `keras.preprocessing_image.py` file in order to
execute these different histogram modification techniques just as we did the out-of-the-box keras augmentations using ImageDataGenerator()




# [Image Augmentation for Deep Learning With Keras](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)

## Saving Augmented Images to File

## Tips For Augmenting Image Data with Keras

Image data is unique in that you can review the data and transformed copies of the data and quickly get an idea of how the model may be perceive it by your model.

Below are some tips for getting the most from image data preparation and augmentation for deep learning.

- Review Dataset. Take some time to review your dataset in great detail. Look at the images. Take note of image preparation and augmentations that might benefit the training process of your model, such as the need to handle different shifts, rotations or flips of objects in the scene.

- Review Augmentations. Review sample images after the augmentation has been performed. It is one thing to intellectually know what image transforms you are using, it is a very different thing to look at examples. Review images both with individual augmentations you are using as well as the full set of augmentations you plan to use. You may see ways to simplify or further enhance your model training process.

- Evaluate a Suite of Transforms. Try more than one image data preparation and augmentation scheme. Often you can be surprised by results of a data preparation scheme you did not think would be beneficial.
